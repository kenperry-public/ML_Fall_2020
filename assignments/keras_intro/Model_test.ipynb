{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# Reload all modules imported with %aimport\n",
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "%aimport helper\n",
    "\n",
    "helper = helper.Helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5eee34a39cd16fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e5cf484e23bf92a6",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "data_dir = np.load('./data/train_test_data.npz')\n",
    "X_train = data_dir['X_train']\n",
    "X_test = data_dir['X_test']\n",
    "y_train = data_dir['y_train']\n",
    "y_test = data_dir['y_test']\n",
    "data = np.concatenate((X_train, X_test))\n",
    "labels = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ef77da961773f303",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Load models and histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9e6c582ae2422565",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "model_name0 = \"Head only\"\n",
    "model0 = helper.loadModel(model_name0)\n",
    "score0 = model0.evaluate(X_test, y_test, verbose=0)\n",
    "history0 = helper.loadHistory(model_name0)\n",
    "\n",
    "model_name1 = \"Dense + Head\"\n",
    "model1 = helper.loadModel(model_name1)\n",
    "score1 = model1.evaluate(X_test, y_test, verbose=0)\n",
    "history1 = helper.loadHistory(model_name1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-77166a20139d67a9",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 1. Model structure test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "build_model_0",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "num_cases = np.unique(labels).shape[0]\n",
    "\n",
    "if num_cases > 2:\n",
    "    activation = \"softmax\"\n",
    "    loss = 'categorical_crossentropy'\n",
    "else:\n",
    "    activation = \"sigmoid\"\n",
    "    num_cases = 1\n",
    "    loss = 'binary_crossentropy'\n",
    "  \n",
    "## Model0 Head Only\n",
    "assert len(model0.layers) <= 3\n",
    "\n",
    "n_samples, width, height = data.shape\n",
    "dense_layer = model0.get_layer(name='dense_head')\n",
    "# Dense layer tests\n",
    "assert dense_layer.input.shape[1:] == tf.TensorShape([ np.prod(data.shape[1:]) ] )\n",
    "assert dense_layer.output.shape[1:] == tf.TensorShape([num_cases])\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "build_model_1",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "num_features_1 = 32\n",
    "\n",
    "dense_1 = model1.get_layer(name='dense_1')\n",
    "dense_head = model1.get_layer(name='dense_head')\n",
    "\n",
    "# Dense 1\n",
    "assert dense_1.input.shape[1:] == tf.TensorShape([ np.prod(data.shape[1:]) ])\n",
    "assert dense_1.output.shape[1:] == tf.TensorShape([num_features_1])\n",
    "\n",
    "# Dense head\n",
    "assert dense_head.output.shape[1:] == tf.TensorShape([num_cases])\n",
    "\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-07b462f71fe2a4aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 2. Training result test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_model_0",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "\n",
    "# Create the key with which to look up accuracy, val_accuracy.  It depends on how the model was compiled.\n",
    "acc_string = helper.acc_key(model=model1)\n",
    "acc_metric, val_acc_metric = acc_string, \"val_\" + acc_string\n",
    "\n",
    "assert history0[ acc_metric ][-1] > 0.6\n",
    "assert history0[ val_acc_metric ][-1] > 0.6\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_model_1",
     "locked": true,
     "points": 15,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert history1[ acc_metric ][-1] > 0.75\n",
    "assert history1[ val_acc_metric ][-1] > 0.75\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "train_model_1_better_than_before",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e545e249652e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### BEGIN HIDDEN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mhistory1\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0macc_metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhistory0\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0macc_metric\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mhistory1\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mval_acc_metric\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mhistory0\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mval_acc_metric\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m### END HIDDEN TESTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert history1[ acc_metric][-1] > history0[ acc_metric ][-1]\n",
    "assert history1[ val_acc_metric ][-1] > history0[ val_acc_metric ][-1]\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b0bb1f19307a3e1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 3. Model parameters number test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "number_params_model_0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert model0.count_params() == ( np.prod(data.shape[1:]) * num_cases + num_cases)\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "number_params_model_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "dense_layers = [layer for layer in model1.layers if 'dense' in layer.name]\n",
    "num_new_parameters = ( np.prod(data.shape[1:]) + 1) * num_features_1 + (num_features_1 + 1) * num_cases\n",
    "\n",
    "if len(dense_layers) == 2:\n",
    "    assert model1.count_params() == num_new_parameters\n",
    "elif len(dense_layers) > 2:\n",
    "    assert model1.count_params() > num_new_parameters\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-95c2e43e19566217",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "evaluate_model_0",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert score0[1] > 0.6\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "evaluate_model_1",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert score1[1] > 0.8\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "evaluate_model_0_better_than_before",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert score1[1] > score0[1]\n",
    "### END HIDDEN TESTS"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
